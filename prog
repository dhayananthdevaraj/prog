13)svm
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn import svm
data = pd.read_csv('irisdata.csv')
x = data['length']
y = data['width']
tr_x = np.vstack((x, y)).T
tr_y = data['Type']
clf = svm.SVC(kernel='linear', C=1.0)
clf.fit(tr_x,tr_y)
w =clf.coef_[0]
a = -w[0] /w[1]
xx = np.linspace(0, 13)
yy = a* xx -clf.intercept_[0] / w[1]
plt.plot(xx,yy,'k-')
plt.scatter(tr_x[:,0],tr_x[:,1],c=tr_y)
plt.show()
---
12)stacking
import sklearn.datasets as sd
import sklearn.model_selection as al
import sklearn.ensemble as se
import sklearn.linear_model as sl
import sklearn.svm as sv
import time
X, Y = sd.load_diabetes(return_X_y=True)
X_train, X_test, Y_train, Y_test = al.train_test_split(X,Y,random_state=42)
stacked = se.StackingRegressor( estimators =[('SVR', sv.SVR()),('Liner',sl.LinearRegression())])
st = time.time()
stacked.fit(X_train, Y_train)
et = time.time()
print("Coefficient of determination: {}".format(stacked.score(X_test, Y_test)))
print("Computation Time: {}".format(et - st))
---
11)Logistic Regression 
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.linear_model import LogisticRegression

data = pd.read_csv('irisdata.csv')
x = data[['length', 'width']]
y = data['Type']
model = LogisticRegression(solver='liblinear', random_state=0)
model.fit(x,y)
z=model.predict(x)
print(z)
plt.plot(z)
plt.show()
---
10)Naive
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
df = pd.read_csv("dataset.csv")
x = df.drop("diabetes",axis=1)
y = df["diabetes"]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)
model = GaussianNB()
model.fit(x_train,y_train)
y_pred=model.predict(x_test)
accuracy=accuracy_score(y_test,y_pred)*100
print(accuracy)
---
9)K- means
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
import sys
x=[4,5,10,4,3,22,2,84]
y=[21,19,24,16,25,24,22,21]
plt.scatter(x,y)
plt.show()
d=list(zip(x,y))
kmeans = KMeans(n_clusters=2)
kmeans.fit(d)
plt.scatter(x,y,c=kmeans.labels_)
plt.show()
plt.savefig(sys.stdout.buffer)
sys.stdout.flush()
---------
8)n csv file and print a list of Strings
import csv
col_names=['Name','Age'];
data=[["Ammaaa",'0'],["Dhayaa",'100']]
file="rec.csv"
with open(file,'w') as csvfile:
    csvwriter=csv.writer(csvfile);
    csvwriter.writerow(col_names)
    csvwriter.writerows(data)
import csv
with open('rec.csv','r') as csvfile:
    rows=csv.reader(csvfile)
    for row in rows:
        print(row)
---
7)k-fold
from numpy import array
from sklearn.model_selection import KFold
data = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6,0.7])
kfold = KFold(3)

for train, test in kfold.split(data):
	print('train: %s, test: %s' % (data[train], data[test]))
--
6)
text=input().lower()
print(text)
l=list(set(text))
if " " in l:
    l.remove(" ")
if len(l)==26:
    print("anangaram")
else:
    print("not an anagaram")
print(l)
--
5)
import pandas as pd
m={"values":[1,2,3,4,5,6,76,78,89,90]}
df=pd.DataFrame(m)
df['sq']=df["values"]**2
print(df)
--
4)
import numpy as np
mat=np.array([[1,2,3],[1,2,3]])
mat1=np.array([[1,2,3],[1,2,3]])
print(np.multiply(mat,mat1))
print(np.divide(mat,mat1))
--
3)
a=(1,2,3,3,5)
print(a[:2])
b=tuple("Dhayaaaaaaaaaaa")
print(b[:])
--
2)
marks=[{
    'name':"daya","m1":33,'m2':99
},{"name":"prasi","m1":99,'m2':88}]
for mark in marks:
    m1=mark.pop('m1');
    m2=mark.pop('m2')
    mark['avg']=(m1+m2)/2
print(marks)
--
1)
l1=[1,2,3,4,5]
l2=[1,2,3,8]
l=len(l2)
count=0
for i in l1:
    for j in l2:
        if i==j:
            count+=1
if count==l:
    print("True")
else:
    print("False")


