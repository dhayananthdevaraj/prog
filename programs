13)svm
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn import svm
data = pd.read_csv('irisdata.csv')
x = data['length']
y = data['width']
tr_x = np.vstack((x, y)).T
tr_y = data['Type']
clf = svm.SVC(kernel='linear', C=1.0)
clf.fit(tr_x,tr_y)
w =clf.coef_[0]
a = -w[0] /w[1]
xx = np.linspace(0, 13)
yy = a* xx -clf.intercept_[0] / w[1]
plt.plot(xx,yy,'k-')
plt.scatter(tr_x[:,0],tr_x[:,1],c=tr_y)
plt.show()
---
12)stacking
import sklearn.datasets as sd
import sklearn.model_selection as al
import sklearn.ensemble as se
import sklearn.linear_model as sl
import sklearn.svm as sv
import time
X, Y = sd.load_diabetes(return_X_y=True)
X_train, X_test, Y_train, Y_test = al.train_test_split(X,Y,random_state=42)
stacked = se.StackingRegressor( estimators =[('SVR', sv.SVR()),('Liner',sl.LinearRegression())])
st = time.time()
stacked.fit(X_train, Y_train)
et = time.time()
print("Coefficient of determination: {}".format(stacked.score(X_test, Y_test)))
print("Computation Time: {}".format(et - st))
---
11)Logistic Regression 
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.linear_model import LogisticRegression

data = pd.read_csv('irisdata.csv')
x = data[['length', 'width']]
y = data['Type']
model = LogisticRegression(solver='liblinear', random_state=0)
model.fit(x,y)
z=model.predict(x)
print(z)
plt.plot(z)
plt.show()
---
10)Naive
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
df = pd.read_csv("dataset.csv")
x = df.drop("diabetes",axis=1)
y = df["diabetes"]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)
model = GaussianNB()
model.fit(x_train,y_train)
y_pred=model.predict(x_test)
accuracy=accuracy_score(y_test,y_pred)*100
print(accuracy)
---
9)K- means
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
import sys
x=[4,5,10,4,3,22,2,84]
y=[21,19,24,16,25,24,22,21]
plt.scatter(x,y)
plt.show()
d=list(zip(x,y))
kmeans = KMeans(n_clusters=2)
kmeans.fit(d)
plt.scatter(x,y,c=kmeans.labels_)
plt.show()
plt.savefig(sys.stdout.buffer)
sys.stdout.flush()
---------
8)n csv file and print a list of Strings
import csv
f=["Name","Rollno"]
ro=[["dhaya","21mca015"],["prasii","21mca042"],["deen","21mca032"]]
with open("rec.csv",'w') as write:
	w=csv.writer(write)
	w.writerow(f)
	w.writerows(ro)
with open("rec.csv",'r') as rea:
	ro = csv.DictReader(rea)
	for rw in ro :
    	print(rw)
---
7)k-fold
from numpy import array
from sklearn.model_selection import KFold
data = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6,0.7])
kfold = KFold(3)

for train, test in kfold.split(data):
	print('train: %s, test: %s' % (data[train], data[test]))
---
6)
import string as s
v=input()
alp=set(s.ascii_lowercase)
print(set(v.lower())>=alp)
--
5)
import pandas as pd
m={"values":[1,2,3,4,5,6,76,78,89,90]}
df=pd.DataFrame(m)
df['sq']=df["values"]**2
print(df)
--
4)
import numpy as np
mat=np.array([[1,2,3],[1,2,3]])
mat1=np.array([[1,2,3],[1,2,3]])
print(np.multiply(mat,mat1))
print(np.divide(mat,mat1))
for i in range(10,0,-1):
	print("count : ",i)
	print(n.multiply(c,i))

--
3)
l=("helloworld","this is from cbe")
for i in l:
	v=tuple(i)
	h=v[::-1]
	print(h)
l2=(1,2,3,4,5,6,7,8,9)
print(type(l))
print(l)
print(l[::-1])
print(l[0:])
print(l[:5])
print(l2[::-1])
print(l2[0:])
print(l2[:5])

--
2)
marks=[{'name':"daya","m1":33,'m2':99},{"name":"prasi","m1":99,'m2':88}]
for mark in marks:
    m1=mark.pop('m1');
    m2=mark.pop('m2')
    mark['avg']=(m1+m2)/2
print(marks)
--
1)
lt=list(map(int,input().split()))
slt=list(map(int,input().split()))
r=len(slt)
c=0
for i in slt:
 for k in range(0,len(lt)):
 	if i == lt[k]:
     	c=c+1
if c==r:
	print("true")
else:
	print("false")

